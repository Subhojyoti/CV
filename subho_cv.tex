\pdfminorversion=4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Medium Length Graduate Curriculum Vitae
% LaTeX Template
% Version 1.2 (3/28/15)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Rensselaer Polytechnic Institute 
% (http://www.rpi.edu/dept/arc/training/latex/resumes/)
%
% Modified by:
% Daniel L Marks <xleafr@gmail.com> 3/28/2015
%
% Important note:
% This template requires the res.cls file to be in the same directory as the
% .tex file. The res.cls file provides the resume style used for structuring the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%-------------------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% You can have multiple style options the legal options ones are:
%
%   centered:	the name and address are centered at the top of the page 
%				(default)
%
%   line:		the name is the left with a horizontal line then the address to
%				the right
%
%   overlapped:	the section titles overlap the body text (default)
%
%   margin:		the section titles are to the left of the body text
%		
%   11pt:		use 11 point fonts instead of 10 point fonts
%
%   12pt:		use 12 point fonts instead of 10 point fonts
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[margin,11pt]{res}  

% Default font is the helvetica postscript font
%\usepackage{helvet}
\usepackage[scaled]{helvet}
\renewcommand\familydefault{\sfdefault} 
\usepackage[T1]{fontenc}

% Increase text height
\textheight=700pt

\usepackage{enumitem}
\usepackage{hyperref}
%\usepackage[none]{hyphenat}

\begin{document}

%-------------------------------------------------------------------------------
%	NAME AND ADDRESS SECTION
%-------------------------------------------------------------------------------
\name{\textsc{Subhojyoti Mukherjee}}
% Note that addresses can be used for other contact information:
% -phone numbers
% -email addresses
% -linked-in profile

%ALL Lab \& Bio-NLP Group\\

\address{College of Information and Computer Sciences \\University of Massachusetts Amherst\\Amherst, MA 01002}
\address{Phone: +1 669 208 8939\\Email: \texttt{subho@cs.umass.edu, } \\ \texttt{subhojyotimukherjee22@gmail.com} \\ Website: \href{https://subhojyoti.github.io/}{https://subhojyoti.github.io/}}

% Uncomment to add a third address
%\address{Address 3 line 1\\Address 3 line 2\\Address 3 line 3}
%-------------------------------------------------------------------------------

\begin{resume}

\section{Research Interests}

Machine learning, Reinforcement learning, Online Learning, Multi-armed bandits, Applied Probability, Optimization.

%\textbf{Broad Areas}: Machine learning, Reinforcement learning.
%
%\par
%\textbf{Working On}: Multi-armed bandits.


%-------------------------------------------------------------------------------
%	EDUCATION SECTION
%-------------------------------------------------------------------------------
\section{Education}
\textbf{University of Massachusetts}, Amherst, USA \hfill Fall 2018 -- current\\
{\sl Ph.D.}, Computer Science \\
CGPA (1st Semester): 4.0/4.0
%Advisers: \href{https://scholar.google.com/citations?user=TyXe64wAAAAJ&hl=en}{Dr. Hong Yu} and \href{https://people.cs.umass.edu/~pthomas/}{Dr. Phillip Thomas}
\\[0.25cm]
\textbf{Indian Institute of Technology Madras}, India\hfill 2015--2018 \\
{\sl M.S (Research)}, Computer Science \\
Advisers: \href{https://www.cse.iitm.ac.in/~ravi/}{Dr.~Balaraman Ravindran} and \href{https://doms.iitm.ac.in/index.php/nandan-s}{Dr.~Nandan Sudarsanam}\\ CGPA: 8.4/10
\\[0.25cm]
\textbf{West Bengal University of Technology}, Kolkata, India\hfill 2009--2013\\
{\sl Bachelor of Technology}, Computer Science \& Engineering\\ CGPA: 8.4/10
%-------------------------------------------------------------------------------
\section{Publications}
\begin{enumerate}[leftmargin=*]
\item \textbf{Subhojyoti Mukherjee}, K.P.~Naveen, Nandan Sudarsanam, and Balaraman Ravindran, ``\textit{Efficient UCBV: An Almost Optimal Algorithm using Variance Estimates}'', \textit{Proceedings of the Thirty-Second Association for the Advancement of Artificial Intelligence \textbf{(AAAI-18)}}, main conference track [Oral].\href{https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16111}{[Paper]}
\item \textbf{Subhojyoti Mukherjee}, K.P.~Naveen, Nandan Sudarsanam, and Balaraman Ravindran, ``\textit{Thresholding Bandits with Augmented UCB}'', \textit{Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence \textbf{(IJCAI-17)}}, main conference track [Oral + Poster]. \href{https://www.ijcai.org/proceedings/2017/0350.pdf}{[Paper]}
\end{enumerate}

\section{Under Review}
\begin{enumerate}
\item \textbf{Subhojyoti Mukherjee}, and Odalric-Ambrym-Maillard, ``\textit{Order Optimal and Time-uniform Bounds for Piecewise i.i.d Bandits}'', \textit{Under Review in Thirty-sixth International Conference on Machine Learning  \textbf{(ICML-19)}}, main conference track. \href{https://github.com/Subhojyoti/INRIA_Intern/blob/master/ICML2019/paper.pdf}{[Paper]}
\item \textbf{Subhojyoti Mukherjee}, Branislav Kveton, and Anup Rao, "\textit{Non-Stochastic Low Rank Bandits}", \textit{Under Review in Twenty-eighth International Joint Conference on Artificial Intelligence \textbf{(IJCAI-19)}}. \href{https://github.com/Subhojyoti/Latent_Bandits/blob/master/IJCAI2019/bandit_paper.pdf}{[Paper]}
\item \textbf{Subhojyoti Mukherjee}, and Odalric-Ambrym-Maillard, "\textit{Variance Aware Changepoint Detection for Piecewise i.i.d Bandits}", \textit{Under Review in Twenty-eighth International Joint Conference on Artificial Intelligence \textbf{(IJCAI-19)}}. \href{https://github.com/Subhojyoti/INRIA_Intern/blob/master/IJCAI\%202019/ijcai19.pdf}{[Paper]}
\end{enumerate}

%---------------------------------------------------------------------------

\section{Research Internships}
\textbf{Adobe Research, San Jose:} Research internship under Dr. Branislav Kveton in the Adobe Research, San Jose, USA from 22nd January, 2018 to 20th April, 2018 for a period of 3 months.

\textbf{INRIA, SequeL Lab:} Research internship under Dr. Odalric Maillard in the INRIA Sequel Lab, Lille, France from 1st September, 2017 to 28th November, 2017 for a period of 3 months.


%----------------------------------------------------


\section{Master's Thesis}

This thesis studies the following topics in the area of Reinforcement Learning: Multi-armed bandits in stationary distribution with the goal of cumulative regret minimization and Thresholding bandits in pure exploration setting. The common underlying theme is the study of bandit theory and its application in various types of environments. In the first part of the thesis, we study the classic multi-armed bandit problem with a stationary distribution, one of the first settings studied by the bandit community and which successively gave rise to several new directions in bandit theory. We propose a novel algorithm in this setting and compare both theoretically and empirically its performance against the available algorithms. Our proposed algorithm termed as Efficient-UCB-Variance (EUCBV) is the first arm-elimination algorithm which uses variance estimation to eliminate arms as well as achieve an order optimal regret bound. Empirically, we show that EUCBV outperforms most of the state-of-the-art algorithms in the considered environments. In the next part, we study a specific type of stochastic multi-armed bandit setup called the thresholding bandit problem and discuss its usage, available state-of-the-art algorithms on this setting and our solution to this problem. We propose the Augmented-UCB (AugUCB) algorithm which again uses variance and mean estimation along with arm elimination technique to conduct exploration. We give theoretical guarantees on the expected loss of our algorithm and also analyze its performance against state-of-the-art algorithms in numerical simulations in multiple synthetic environments. \href{https://subhojyoti.github.io/pdf/final_thesis(A5)_Subhojyoti_CS15S300.pdf}{[Thesis]}


%\section{B.Tech Project}
%
%This project studies the area of Sentiment Analysis in Natural Language Processing. Identifying the sentiment of a movie review or a product review from user comments forms a vital form of feedback in recommender systems. The learning algorithm can use this feedback to understand the recent trends and then suggest an interesting item to a user that will generate its interest. We develop an algorithm that takes input a recent trending topic in the internet which then crawls the Twitter in identifying the sentiments of the user regarding the topic from their associated tweets and then outputs whether the general sentiment is positive, negative or neutral regarding the topic. The algorithm uses bag-of-words model where it uses several existing dictionaries to store the sentiment of words before-hand to output the general sentiment regarding the topic.



\section{Research Projects}
%\par 
%\textbf{Efficient Clustered UCB}\\
%Presented a novel algorithm for the stochastic multi-armed bandit (MAB) problem. Our proposed Efficient Clustered UCB method partitions the arms into clusters and then follows the UCB-Improved strategy with aggressive exploration factors to eliminate sub-optimal arms, as well as entire clusters. Through a theoretical analysis, we establish that our method achieves a better gap-dependent regret upper bound than UCB-Improved and MOSS algorithms.
\par 

\textbf{Thresholding Bandits with Augmented UCB}\\
Proposed the Augmented-UCB (AugUCB) algorithm for a fixed-budget version of the thresholding bandit problem (TBP), where the objective is to identify a set of arms whose quality is above a threshold. A key feature of AugUCB is that it uses both mean and variance estimates to eliminate arms that have been sufficiently explored. This is the first algorithm to employ such an approach for the considered TBP setting. \href{https://www.ijcai.org/proceedings/2017/0350.pdf}{[Paper]}
\par

\textbf{Efficient UCBV: An Almost Optimal Algorithm using Variance Estimates}\\
Presented a novel algorithm for the stochastic multi-armed bandit (MAB) problem. Our proposed Efficient UCB Variance method, referred to as EUCBV is an arm elimination algorithm based on UCB-Improved and UCBV strategy which takes into account the empirical variance of the arms and along with aggressive exploration factors eliminate sub-optimal arms. Through a theoretical analysis, we establish that EUCBV achieves a better gap-dependent regret upper bound than UCB-Improved, MOSS, UCB1, and UCBV algorithms. EUCBV enjoys an order optimal gap-independent regret bound same as that of OCUCB and MOSS, and better than UCB-Improved, UCB1 and UCBV. \href{https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16111}{[Paper]}
\par

\textbf{Order Optimal and Time-uniform Bounds for Piecewise i.i.d Bandits}\\
We consider the setup of stochastic multi-armed bandits in the case when reward distributions are piecewise i.i.d. and bounded with unknown changepoints. We focus on the case when changes happen simultaneously on all arms, and in stark contrast with the existing literature, we target gap-dependent (as opposed to only gap-independent) regret bounds involving the magnitude of changes $(\Delta^{chg}_{i,g})$ and optimality-gaps ($\Delta^{opt}_{i,g}$). Under a slightly stronger set of assumptions, we show that as long as the compounded delayed detection for each changepoint is bounded there is no need for extra exploration to actively detect changepoints. We introduce two adaptations of UCB-strategies that employ scan-statistics in order to actively detect the changepoints, without knowing in advance the changepoints and also the mean before and after any change. Our first method UCBLaplace-CPD does not know the number of changepoints $G$ or time horizon $T$ and achieves the first time-uniform concentration bound for this setting using the Laplace method of integration. The second strategy ImpCPD makes use of the knowledge of $T$ to achieve the order optimal regret bound of $\min\big\lbrace O(\sum_{i=1}^{K} \sum_{g=1}^{G}\frac{\log(T/H_{1,g})}{\Delta^{chg}_{i,g}}), O(\sqrt{GT})\big\rbrace$, (where $H_{1,g}$ is the problem complexity) thereby closing an important gap with respect to the lower bound in a specific setting. Our theoretical findings are supported by numerical experiments on synthetic and real-life datasets. \href{https://github.com/Subhojyoti/INRIA_Intern/blob/master/ICML2019/paper.pdf}{[Paper]}

%to remove the $\log T$ dependency thereby closing an important gap with respect to the lower bound.
%
%We introduce two simple adaptations of UCB-strategies that employ scan-statistics in order to actively detect the changepoints, without knowing in advance the number of changepoints $G$. 
%    We also derive gap-independent regret bounds. The first strategy UCB-CPD does not know the time horizon $T$ and achieve a $O(\sqrt{GT}\log T)$ regret bound, while the second strategy ImpCPD makes use of the knowledge of $T$ to remove the $\log T$ dependency thereby closing an important gap with respect to the lower bound. Empirically, ImpCPD outperforms most of the passive and adaptive algorithms except the oracle-based algorithms that have access to the exact changepoints in all the considered environments.

\textbf{Non-Stochastic Low Rank Bandit}\\
We study the problem of learning the maximum entry of a low-rank non-negative matrix, from sequential observations. In this setting, the learner chooses tuples of rows and columns at every round and observes the product of their values. The main challenge in this setting is that the learner does not observe the individual latent values of rows and columns as its feedback. Diverging from previous works we assume that the preference matrix is non-stochastic and hence our setting is more general in nature. Existing methods for solving similar problems rely on UCB-type algorithms based on constructing conservative confidence intervals with the strong assumption that underlying distributions are stochastic. We depart from this standard approach and consider the case when the best row and column pair can be learned jointly with help of two separate bandit algorithms working individually on rows and columns. We propose a simple and computationally efficient algorithm that implements this procedure, which we call Low Rank Bandit, and prove a sub-linear bound on its $n$-step regret in the rank-$1$ special case. We evaluate the algorithm empirically on several synthetic and real-world datasets. In all experiments, we outperform existing state-of-the-art algorithms. \href{https://github.com/Subhojyoti/Latent_Bandits/blob/master/IJCAI2019/bandit_paper.pdf}{[Report]}

%\textbf{Conservative Bandits}\\
%We study 

\section{Collaborators}
\begin{enumerate}
\item Dr. Balaraman Ravindran, CSE Department, IIT Madras
\item Dr. Nandan Sudarsanam, Department of Management Science, IIT Madras
\item Dr. K.P. Naveen, Deprtment of Electrical Engineering, IIT Tirupati
\item Dr. Odalric-Ambrym Maillard, INRIA, SequeL Lab, Lille, France
\item Dr. Branislav Kveton, Google Research, Mountain View, USA
\item Dr. Anup Rao, Adobe Research, San Jose, USA
\end{enumerate}

\section{Teaching Experience}
\par
\textbf{Teaching Assistant}, UMass Amherst\hfill 2018--current\\
\textbf{Teaching Assistant}, IIT Madras\hfill 2015--2018\\
Assisted in preparing and conducting lab assignments and class tutorials for the following courses:\\
\textit{Natural Language Processing} - Prof.~Mohit Iyyer\\
\textit{Introduction to Programming} - Prof.~Raghavendra Rao B. V. \\
\textit{Reinforcement Learning}(twice) - Prof.~Balaraman Ravindran\\
\textit{Compiler Design} - Prof.~Rupesh Nasre

\section{Work Experience}
\textbf{Tata Consultancy Services Ltd.}, Kolkata, India\hfill March 2014--December 2014\\
\textit{Assistant System Engineer Trainee}\\
Software development and test engineer in Digital Enterprise Service and Solution.

% \section{AWARDS}
% \textbf{Doctoral Consortium Participation and Travel Award} at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2016\\
% \textbf{Institute Research Scholar Award} for excellence in research awarded by IIT Madras in April 2015

\section{Professional Activities}
\textbf{Reviewer} 
\begin{enumerate}
\item Assisted Dr.~Balaraman Ravindran in reviewing for IJCAI 2017.
\item Assisted Dr.~Branislav Kveton in reviewing for ICML 2018.
\end{enumerate}

\textbf{Volunteer} 
\begin{enumerate}
\item Assisted Dr.~Balaraman Ravindran in conducting the \textit{"Recent Advances in Reinforcement Learning, 2015"} workshop held at IIT Madras. Some of the key speakers include, Dr. Richard Sutton, Dr. Csaba Szepesvari, Dr. Sridhar Mahadevan, and Dr. Satindar Singh.
\end{enumerate}


\section{Relevant Coursework [\href{https://github.com/Subhojyoti/subhojyoti.github.io/blob/master/pdf/Courses\%20Information.pdf}{more information}]}
\begin{tabular}{ll}
Introduction to Machine Learning & Reinforcement Learning  \\
Natural Language Processing & Linear Algebra and Random Processes \\
Multi-variate Data Analysis & Data Analysis for Research \\
Artificial Intelligence & Design and Analysis of Algorithms \\
%\multicolumn{2}{l}{Artificial Intelligence}
\end{tabular}

\section{Award and Grants}
\begin{enumerate}
\item Our paper titled "Thresholding Bandits with Augmented UCB" was awarded IIT Madras student travel grant of USD $2300$.
\item Our paper titled "Efficient UCBV: An Almost Optimal Algorithm using Variance Estimates" was awarded Google travel grant of USD $1700$, AAAI grant of USD $500$ and Microsoft travel grant of USD $1435$.
\end{enumerate}


\section{Other Achievements}
\begin{tabular}{p{12cm}p{80cm}}
Scored 318/340 in Graduate Record Examinations \textbf{(GRE)} 2018.\\
Scored 111/120 in Test of English as a Foreign Language \textbf{(TOEFL)} 2017.\\
Ranked 1150/155190 candidates in Graduate Aptitude Test in Engineering \textbf{(GATE)} 2014. \\
Secured 98.93 percentile in Common Admission Test \textbf{(CAT)} 2014 among 196988 candidates.
\end{tabular}

%\newpage
\section{References}
\begin{tabular}{lll}
\textbf{Dr.~Balaraman Ravindran} & \textbf{Dr.~Nandan Sudarsanam} \\
Professor & Assistant Professor\\
\texttt{ravi@cse.iitm.ac.in} & \texttt{nandan@iitm.ac.in}\\
Department of Computer Science \& Engg. & Department of Management Studies\\ 
Indian Institute of Technology Madras & Indian Institute of Technology Madras\\
\\
\textbf{Dr.~K.P. Naveen}  & \textbf{Dr.~Odalric Maillard} \\
Assistant Professor & INRIA Researcher (CR1) \\
\texttt{naveenkp@iittp.ac.in} & \texttt{odalricambrym.maillard @ inria.fr}\\
Department of Electrical Engg. & SequeL Team \\ 
Indian Institute of Technology Tirupati & INRIA Lille, France\\
\\
\textbf{Dr.~Branislav Kveton}\\
Machine Learning Scientist\\
\texttt{kveton@google.com}\\
Google Research, Mountain View, CA, USA
\end{tabular}



\end{resume}
\end{document}